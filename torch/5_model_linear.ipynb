{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uoHKHm-cLx68"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C6F4WodyMeGp"
      },
      "outputs": [],
      "source": [
        "weight=0.7\n",
        "bias=0.3\n",
        "start=0\n",
        "end=1\n",
        "step=0.02\n",
        "X=torch.arange(start,end,step).unsqueeze(dim=1)\n",
        "y=weight*X+bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "69N174QTMgsr"
      },
      "outputs": [],
      "source": [
        "train_split=int(0.8*len(X))\n",
        "x_train,y_train=X[:train_split],y[:train_split]\n",
        "x_test,y_test=X[train_split:],y[train_split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU_NbVroNSih",
        "outputId": "de1dd9fb-cb0d-4931-b882-781e70a8c402"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "             ('linear_layer.bias', tensor([0.8300]))])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class LinearRegressionModelV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #use nn.Linear() for creating the model parameters\n",
        "        #infeatures=input=1 (x) outfeatures=1(y)\n",
        "        self.linear_layer=nn.Linear(in_features=1,out_features=1)\n",
        "    def forward(self,x:torch.Tensor)->torch.Tensor:\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model1=LinearRegressionModelV2()\n",
        "model1.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BURAoj4KN4uc",
        "outputId": "fff23ee9-69f2-49c7-d09f-5f90fb804426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(model1.parameters()).device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Avo08bfuOQ9U"
      },
      "outputs": [],
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6p92osvOJty",
        "outputId": "462d4302-c016-4f1e-cd75-4ba109bba371"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegressionModelV2(\n",
              "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lb1svYmMOPZO"
      },
      "outputs": [],
      "source": [
        "loss_fn=nn.L1Loss()\n",
        "optimizer=torch.optim.SGD(params=model1.parameters(),lr=0.01)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvq8KvkrO5QF",
        "outputId": "71b83b36-ac20-4b32-cb82-b5c9eda88853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:0 Loss:0.5551779866218567 test  Loss : 0.5739762187004089\n",
            "epoch:10 Loss:0.4399680495262146 test  Loss : 0.4392663538455963\n",
            "epoch:20 Loss:0.3247582018375397 test  Loss : 0.30455657839775085\n",
            "epoch:30 Loss:0.20954827964305878 test  Loss : 0.16984674334526062\n",
            "epoch:40 Loss:0.09433844685554504 test  Loss : 0.03513689711689949\n",
            "epoch:50 Loss:0.023886386305093765 test  Loss : 0.04784906655550003\n",
            "epoch:60 Loss:0.0199567973613739 test  Loss : 0.04580312222242355\n",
            "epoch:70 Loss:0.016517987474799156 test  Loss : 0.0375305712223053\n",
            "epoch:80 Loss:0.013089170679450035 test  Loss : 0.029944902285933495\n",
            "epoch:90 Loss:0.009653178043663502 test  Loss : 0.02167237363755703\n",
            "epoch:100 Loss:0.006215679459273815 test  Loss : 0.014086711220443249\n",
            "epoch:110 Loss:0.002787243574857712 test  Loss : 0.005814164876937866\n",
            "epoch:120 Loss:0.0012645035749301314 test  Loss : 0.013801807537674904\n",
            "epoch:130 Loss:0.0012645035749301314 test  Loss : 0.013801807537674904\n",
            "epoch:140 Loss:0.0012645035749301314 test  Loss : 0.013801807537674904\n",
            "epoch:150 Loss:0.0012645035749301314 test  Loss : 0.013801807537674904\n",
            "epoch:160 Loss:0.0012645035749301314 test  Loss : 0.013801807537674904\n",
            "epoch:170 Loss:0.0012645035749301314 test  Loss : 0.013801807537674904\n",
            "epoch:180 Loss:0.0012645035749301314 test  Loss : 0.013801807537674904\n",
            "epoch:190 Loss:0.0012645035749301314 test  Loss : 0.013801807537674904\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "epochs=200\n",
        "for epoch in range(epochs):\n",
        "  model1.train()\n",
        "  y_pred=model1(x_train)\n",
        "  loss=loss_fn(y_pred,y_train)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  #In PyTorch, optimizer.step() is a method that updates the\n",
        "  #parameters of your model based on the computed gradients.\n",
        "  model1.eval()  # Set model to evaluation mode (no gradients, dropout disabled)\n",
        "  with torch.inference_mode(): # Disable gradient tracking during inference\n",
        "    test_pred=model1(x_test)\n",
        "    test_loss=loss_fn(test_pred,y_test)\n",
        "  if epoch % 10 ==0:\n",
        "    print(f\"epoch:{epoch} Loss:{loss} test  Loss : {test_loss}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8qK60enO-AX",
        "outputId": "9cd6a948-e0f4-4b72-b6ff-bb615656a9ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.6968]])),\n",
              "             ('linear_layer.bias', tensor([0.3025]))])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REx6M9ZNRGPm",
        "outputId": "3cdb740e-2355-406a-e44a-fd93585c63b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.7, 0.3)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weight,bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Kn_Rt3hkRI0I"
      },
      "outputs": [],
      "source": [
        "## making and evaluating predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx-dlOikRbYj",
        "outputId": "e18b583d-ce5f-4387-9647-c9fbc14c9f10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8600],\n",
              "        [0.8739],\n",
              "        [0.8878],\n",
              "        [0.9018],\n",
              "        [0.9157],\n",
              "        [0.9296],\n",
              "        [0.9436],\n",
              "        [0.9575],\n",
              "        [0.9714],\n",
              "        [0.9854]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.eval()\n",
        "with torch.inference_mode():\n",
        "  y_preds=model1(x_test)\n",
        "y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAun_IWSSGip"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
