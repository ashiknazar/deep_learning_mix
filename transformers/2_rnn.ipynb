{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn](images/rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- deals with sequence data give rise to several types of architectures\n",
    "  - vectors to sequence models\n",
    "  - sequence to vector models\n",
    "  - sequence to sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rnns are good with time series data\n",
    "- but they are slow \n",
    "  - use truncated version of back propagation to train it\n",
    "  - long sequences lead to vanishing / exploding gradients\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is the Vanishing Gradient Problem?</b>\n",
    "- Gradient Descent: Neural networks are typically trained using gradient descent, which involves calculating the gradient (partial derivative) of the loss function with respect to the weights. These gradients are used to update the weights to minimize the loss.\n",
    "- Backpropagation: During backpropagation, the gradients are propagated backward through the layers of the network. For each layer, the gradient is calculated based on the gradients from the subsequent layer.\n",
    "- Vanishing Gradients: In deep networks, especially those with many layers, the gradients can become very small as they are propagated back. This can lead to weights in the earlier layers receiving tiny updates, effectively causing them to learn very slowly or not at all. This phenomenon is referred to as the \"vanishing gradient problem.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Does It Occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> Activation Functions:</b> Certain activation functions, like the sigmoid or hyperbolic tangent (tanh), can cause gradients to shrink significantly when inputs are far from zero. \n",
    "- <b>Chain Rule:</b> The gradient calculation involves multiplying gradients through the layers. If the gradients at any layer are small, this can lead to a compounded effect, resulting in very small gradients as they are propagated backward.\n",
    "- <b>Weight Initialization: </b>Poor initialization of weights can exacerbate the vanishing gradient problem. If weights are initialized too small, the activations will be small, leading to small gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Exploding Gradient Problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Gradient Descent:</b> Similar to the vanishing gradient problem, the exploding gradient problem occurs during the backpropagation phase of training, where gradients are computed and used to update the network's weights.\n",
    "- <b>Gradients Explosion: </b>In this case, instead of gradients becoming very small (as in the vanishing gradient problem), they grow excessively large. This can cause the weight updates to become too large, leading to instability during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- The exploding gradient problem refers to a situation where the gradients of the loss function become excessively large during backpropagation. This can lead to significant instability in the training process, causing the model's weights to change dramatically and preventing it from converging to a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### How It Happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forward Propagation:\n",
    "\n",
    "   - In forward propagation, inputs are passed through the network, and each layer applies weights to the inputs, producing outputs that serve as inputs for the next layer.\n",
    "   - If the weights in any layer are initialized to large values, the outputs can grow quickly. For example, if a layer has weights initialized around 10, even a small input can lead to large outputs.\n",
    "- Backpropagation:\n",
    "\n",
    "    - After computing the loss (the difference between the predicted output and the actual target), backpropagation computes gradients to update the weights.\n",
    "\n",
    "    - Using the chain rule, gradients are propagated backward through the network. If the output of a layer is large due to large weights or activations, the gradients can also become large.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn](images/exp_grad.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VANISHING GRADIENT /EXPLODING GRADIENT PROBLEMS \n",
    "<BR><b> This lead to introduction of LSTM</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next Page lstm](3_lstm.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
