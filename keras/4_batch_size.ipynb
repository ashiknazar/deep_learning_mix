{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In machine learning, batch size refers to the number of data samples that the model processes at one time before updating its internal parameters (weights and biases). It is a key concept during the training phase of a model and has a significant impact on how the model learns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Training Process:**\n",
    "\n",
    "- During training, the model uses a dataset to learn patterns.\n",
    "- The dataset is typically too large to process all at once, so it is divided into smaller parts called batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Batch Size:**\n",
    "\n",
    "The batch size determines how many samples are in each batch.\n",
    "After processing one batch, the model calculates the loss and updates its weights using a process called backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Why Use Batches?**\n",
    "\n",
    "- Memory Efficiency: Loading the entire dataset at once might exceed memory limits, especially for large datasets.\n",
    "- Optimization Stability: Smaller batches can introduce some randomness, which may help the model escape local minima during optimization.\n",
    "- Parallel Processing: Modern hardware, like GPUs, can process batches in parallel, speeding up training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Learning Based on Batch Size:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Batch Gradient Descent:**\n",
    " - Uses the entire dataset as one batch.\n",
    " - Very stable but slow and memory-intensive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Stochastic Gradient Descent (SGD):**\n",
    "\n",
    "- Batch size = 1 (each sample updates the weights).\n",
    "- Faster updates but can be noisy and unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Mini-Batch Gradient Descent:**\n",
    "\n",
    "- Batch size > 1 but less than the full dataset (e.g., 32, 64, 128).\n",
    "- Combines the benefits of both approaches, providing a balance between speed and stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
